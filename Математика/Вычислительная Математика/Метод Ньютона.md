---
tags: математика вычислительная_математика метод_решения система_линейных_алгебраических_уравнений(СЛАУ) система_нелинейных_алгебраических_уравнений(СНАУ)
---
# Метод Ньютона:
Один из [[Итерационные Методы Решения|итерационных]] [[Методы Решения СНАУ|методов решения систем нелинейных алгебраических уравнений]] ([[Система Нелинейных Алгебраических Уравнений (СНАУ)|СНАУ]]) (но в принципе его можно применить и для [[Методы Решения СЛАУ|решения систем линейных алгебраических уравнений]] ([[Системы Линейных Алгебраических Уравнений (СЛАУ)|СЛАУ]])).

Также частный случай метода Ньютона используется при [[Приближенное Решение|приближенном]] [[Методы Приближенного Решения Нелинейных Алгебраических Уравнений|решении]] [[Нелинейное Алгебраическое Уравнение (НАУ)|нелинейного алгебраического уравнения]] [[Метод Касательных-Ньютона|методом касательных]] и [[Комбинированный Метод Хорд и Касательных-Ньютона|комбинированным методом хорд и касательных]].

Основывается на построении векторной последовательности [[Приближенное Решение|приближенных решений]] $x^0, x^1, ..., x^k, x^{k+1},...$, предел которых сходится с [[Точное Решение|точным решением]] $x^*$.

По методу мы находим значение вектора [[Приближенное Решение|приближенного решения]] $x^{k+1}$ через предыдущий вектор [[Приближенное Решение|приближенного решения]] $x^k$.

$x^0$ - произвольно задаётся перед началом метода (значение элементов вектора не имеет значения).

Критерий остановки метода; $||x^* - \tilde{x}|| \leq \epsilon$, где операция $||x||$ - операция нахождения любой [[Норма (числовая характеристика)|нормы]] вектора, $\epsilon$ - [[Допустимая Числовая Погрешность|допустимая числовая погрешность]].

Вид [[Система Нелинейных Алгебраических Уравнений (СНАУ)|СНАУ]]:
$$\Bigg\{\,\begin{array}{rcl}
	f_1(x_1,x_2,...,x_n) = 0 \\
	f_2(x_1,x_2,...,x_n) = 0 \\
	... \\
	f_n(x_1,x_2,...,x_n) = 0 \\
\end{array}$$

## Выражение необходимого тождества:
При произвольном $n$, функция нахождения следующего неизвестного вектора из векторной последовательности: $f_i(x^{k+1}) = \sum^n_{j=1}{\frac{\sigma f_i(x^k)}{\sigma x_j}\cdot (x_j^{k+1} - x_j^k)}=0$, из которой мы и выражаем $x^{k+1}$ через $\varphi(x_k)$.
Где:
- $i = 1,2,...,n$;
- $x_j$ - определенный элемент вектора $x$;
- $\frac{\sigma f_i(x^k)}{\sigma x_j}$ - производная от $f_i(x^k)$ по переменной $x_j$.

Функция выражается с помощью [[Ряд Тейлора|ряда Тейлора]]:
![[Pasted image 20220403154738.png]]
Для сравнения [[Ряд Тейлора|ряд Тейлора]] выглядит так:
![[Pasted image 20220403154818.png]]

Из чего вытекает критерий использования:
Каждый элемент $F(x)$ - непрерывен и достаточно гладкий (непрерывно дифференцируема необходимое количество раз, в данном случае первые производные существуют и непрерывны)

Для дальнейшего понимания вот примеры для $n = 2$ и $n = 3$ соответственно:
![[Pasted image 20220403155341.png]]
![[Pasted image 20220403155414.png]]

![[Pasted image 20220403155533.png]]
![[Pasted image 20220403155548.png]]

Теперь пусть $n$ будет произвольным, обозначим матрицу системы $\sum^n_{j=1}{\frac{f_i(x^k)}{\sigma x_j}\cdot (x_j^{k+1} - x_j^k)} + f_i(x^k) = 0$ в качестве [[Матрица Якоби|матрицы Якоби]]:
![[Pasted image 20220403155857.png]]
Тогда [[Системы Линейных Алгебраических Уравнений (СЛАУ)|СЛАУ]] выше выглядит в матричной форме как:
![[Pasted image 20220403160043.png]]

Откуда мы и получаем нашу конечную необходимую формулу выражения $x^{k+1}$ через $x^k$:
$x^{k+1} = [\Gamma (x^k)]^{-1} \cdot (\Gamma (x^k)x^k - F(x^k))$ которую в свою очередь можно сократить к виду: $x^{k+1} =  x^k - [\Gamma (x^k)]^{-1}\cdot F(x^k)$. Данное уравнение является оптимальным при решении [[Системы Линейных Алгебраических Уравнений (СЛАУ)|СЛАУ]] и [[Система Нелинейных Алгебраических Уравнений (СНАУ)|СНАУ]] методом Ньютона.

Однако на практике применение формулы выше осложняется задачей нахождения обратной [[Матрица Якоби|матрицы Якоби]] на каждой итерации, поэтому на практике используется модифицированная формула:
$x^{k+1} = [\Gamma (x^0)]^{-1} \cdot (\Gamma (x^0)x^k - F(x^k))$, которую тоже можно сократить к виду: $x^{k+1} =  x^k - [\Gamma (x^0)]^{-1}\cdot F(x^k)$.
Формула выше приводит к большему количеству итераций (так как скорость схождения числового ряда будет линейной по сравнению с оригинальной формулой) и не факт, что векторный ряд сойдётся. Однако задача значительно упрощается, так как не надо находить обратную [[Матрица Якоби|матрицу Якоби]] на каждой итерации (в случае неудачи схождения можно просто поменять изначальный вектор $x^0$).

## Условия сходимости:
Невероятно сложное, но вот оно:
Пусть выполнены условия:
1) Функции $F_i(x)$ - непрерывны ($i = 1,2,...,n$);
2) Функции $F_i(x)$ - непрерывно дважды и одно дифференцируемы ($i = 1,2,...,n$);
3) Существует $[\Gamma(x^0)]^{-1}$;
4) $x^0 \in \Omega \leftrightarrow ||x^* - x^0|| \leq S$, где $\Omega$ - некоторая окружность вокруг [[Точное Решение|точного решения]] $x^*$, $S$ - размер окружности $\Omega$;
5) Существует $[\Gamma(x^k)]_i^{-1}$, причем $||[\Gamma(x^0)]^{-1}|| \leq A_0$, где $A_0$ - некоторая константа, ограничивающая норму обратной [[Матрица Якоби|матрицы Якоби]];
6) $||[\Gamma(x^0)]^{-1} \cdot F(x^0)|| \leq B_0 \leq \frac{\sigma}{2}$, где $B_0$ - некоторая константа, ограничивающая производную [[Матрица Якоби|матрицы Якоби]];
7) $\sum^n_{k=1}{|\frac{\sigma^2 F_i(x)}{\sigma x_j \sigma x_k}|} \leq C$, где $i,j = 1,2,...,n$, $C$ - некоторая константа, ограничивающее выражение;
8) $A_0, B_0, C$ удовлетворяют условию $\mu_0 = 2nA_0B_0C \leq 1$;

Тогда последовательность ${x^k}$ сходится к $x^*$: $x^* = lim_{k \rightarrow \infty}x^k$. При этом $||x^* - x^k|| \leq (\frac{1}{2})^{k-1} \mu_0^{2^k-1} B_0$.

Однако на практике метод применяется с надеждой, что все будет хорошо.
Если что-то не сошлось, то изначальный вектор $x^0$ двигают пока все не будет хорошо.

## Алгоритм на практике:
### Искомая информация:
* [[Система Нелинейных Алгебраических Уравнений (СНАУ)|СНАУ]] в матричной форме: $F(x) = \oslash$;
* Произвольно заданный изначальный вектор [[Приближенное Решение|приближенного решения]] $x^0$;
* $\epsilon$ - [[Допустимая Числовая Погрешность|допустимая числовая погрешность]];
* Итерационная формула $x^{k+1}$ через $x^k$ в матричной форме: $x^{k+1} =  x^k - [\Gamma (x^k)]^{-1}\cdot F(x^k)$, где $\Gamma(x^k)$ - матрица Якоби вида:
![[Pasted image 20220403155857.png]]
* Если не хочется постоянно вычислять обратную [[Матрица Якоби|матрицу Якоби]] на каждой итерации, то можно использовать модифицированную формулу: $x^{k+1} =  x^k - [\Gamma (x^0)]^{-1}\cdot F(x^k)$. Однако эта функция приводит к большему количеству итераций и необязательно сходится (можно менять изначальный вектор $x^0$ пока не сойдётся).
### Критерии использования:
На практике мы применяем метод и надеемся, что он сработает, если не срабатывает то меняем изначальный вектор $x^0$.
Но если мы не можем позволить лишние выборки изначального вектора $x^0$ то мы можем применить следующие условия, чтобы убедиться, что векторный ряд сойдётся:

Пусть выполнены условия:
1) Функции $F_i(x)$ - непрерывны ($i = 1,2,...,n$);
2) Функции $F_i(x)$ - непрерывно дважды и одно дифференцируемы ($i = 1,2,...,n$);
3) Существует $[\Gamma(x^0)]^{-1}$;
4) $x^0 \in \Omega \leftrightarrow ||x^* - x^0|| \leq S$, где $\Omega$ - некоторая окружность вокруг точного решения $x^*$, $S$ - размер окружности $\Omega$;
5) Существует $[\Gamma(x^k)]_i^{-1}$, причем $||[\Gamma(x^0)]^{-1}|| \leq A_0$, где $A_0$ - некоторая константа, ограничивающая норму обратной матрицы Якоби;
6) $||[\Gamma(x^0)]^{-1} \cdot F(x^0)|| \leq B_0 \leq \frac{\sigma}{2}$, где $B_0$ - некоторая константа, ограничивающая производную матрицы Якоби;
7) $\sum^n_{k=1}{|\frac{\sigma^2 F_i(x)}{\sigma x_j \sigma x_k}|} \leq C$, где $i,j = 1,2,...,n$, $C$ - некоторая константа, ограничивающее выражение;
8) $A_0, B_0, C$ удовлетворяют условию $\mu_0 = 2nA_0B_0C \leq 1$;

Тогда последовательность ${x^k}$ сходится к $x^*$: $x^* = lim_{k \rightarrow \infty}x^k$.
При этом $||x^* - x^k|| \leq (\frac{1}{2})^{k-1} \mu_0^{2^k-1} B_0$.

### Ход алгоритма:
1) Произвольно выбираем изначальный вектор $x^0$;
2) Вычисляем $x^{k+1}$ через $x^k$ по формуле:
	1) $x^{k+1} =  x^k - [\Gamma (x^0)]^{-1}\cdot F(x^k)$ если нам не хочется каждый раз вычислять обратную [[Матрица Якоби|матрицу Якоби]];
	2) $x^{k+1} =  x^k - [\Gamma (x^k)]^{-1}\cdot F(x^k)$ в противном случае.
3) Повторяем шаг $2$ пока $||x^{k+1} - x^k|| \geq \epsilon$, где $||x||$ - любая [[Норма (числовая характеристика)|норма]] вектора $x$, $\epsilon$ - [[Допустимая Числовая Погрешность|допустимая числовая погрешность]];
4) Если шагов слишком много (ряд векторов не сходится), то возвращаемся на шаг $1$ и заново выбираем произвольный вектор $x^0$;
5) В итоге получаем вектор [[Приближенное Решение|приближенного решения]] $x^{k+1}$.